theta2[a,b] = theta[a,b] - alpha*gradient;
}
for(a in 1:classes){
denom = 0
num= 0;
for(c in 1:classes){
denom = denom + 2.72^(t(theta[c,])%*%x[example,])
}
for(b in 1:feature){
#b=b+1;
num = 2.72^(t(theta[a,])%*%x[example,])
prob = num/denom
gradient = x[example,b]*(til[example,a]-prob)
theta2[a,b] = theta[a,b] - alpha*gradient;
}
for(a in 1:classes){
denom = 0
num= 0;
for(c in 1:classes){
denom = denom + 2.72^(t(theta[c,])%*%x[example,])
}
for(b in 1:feature){
#b=b+1;
num = 2.72^(t(theta[a,])%*%x[example,])
prob = num/denom
gradient = x[example,b]*(til[example,a]-prob)
theta2[a,b] = theta[a,b] - alpha*gradient;
}
for(a in 1:classes){
denom = 0
num= 0;
for(c in 1:classes){
denom = denom + 2.72^(t(theta[c,])%*%x[example,])
}
for(b in 1:feature){
#b=b+1;
num = 2.72^(t(theta[a,])%*%x[example,])
prob = num/denom
gradient = x[example,b]*(til[example,a]-prob)
theta2[a,b] = theta[a,b] - alpha*gradient;
}
for(a in 1:classes){
denom = 0
num= 0;
for(c in 1:classes){
denom = denom + 2.72^(t(theta[c,])%*%x[example,])
}
for(b in 1:feature){
#b=b+1;
num = 2.72^(t(theta[a,])%*%x[example,])
prob = num/denom
gradient = x[example,b]*(til[example,a]-prob)
theta2[a,b] = theta[a,b] - alpha*gradient;
}
for(a in 1:classes){
denom = 0
num= 0;
for(c in 1:classes){
denom = denom + 2.72^(t(theta[c,])%*%x[example,])
}
for(b in 1:feature){
#b=b+1;
num = 2.72^(t(theta[a,])%*%x[example,])
prob = num/denom
gradient = x[example,b]*(til[example,a]-prob)
theta2[a,b] = theta[a,b] - alpha*gradient;
}
for(a in 1:classes){
denom = 0
num= 0;
for(c in 1:classes){
denom = denom + 2.72^(t(theta[c,])%*%x[example,])
}
for(b in 1:feature){
#b=b+1;
num = 2.72^(t(theta[a,])%*%x[example,])
prob = num/denom
gradient = x[example,b]*(til[example,a]-prob)
theta2[a,b] = theta[a,b] - alpha*gradient;
}
}
theta = theta2;
example = example+1
for(a in 1:classes){
denom = 0
num= 0;
for(c in 1:classes){
denom = denom + 2.72^(t(theta[c,])%*%x[example,])
}
for(b in 1:feature){
#b=b+1;
num = 2.72^(t(theta[a,])%*%x[example,])
prob = num/denom
gradient = x[example,b]*(til[example,a]-prob)
theta2[a,b] = theta[a,b] - alpha*gradient;
}
}
theta = theta2;
example = example+1
#!/usr/bin/env Rscript
# your code must have this first line.
# Train code for logistic regression part goes here
args <- commandArgs(trailingOnly = TRUE)
file_name <- args[1]
modeltheta <- args[2]
file_name  = "H:/R workspace/assnmt2/files1/input22.csv";
modeltheta = "sol.txt";
input <- read.table(file_name,header = FALSE,sep = ",")
mat <- as.matrix(input);
dimn = dim(mat)
m = dimn[1]
n = dimn[2]-1
y = mat[,n+1]
mat = mat[,-(n+1)]
x = t(t(mat));
##################create more feature here if want
#for(j in 1:n){
#}
#dimn = dim(x)
#m = dimn[1]
#n = dimn[2]
#-----------------------------------------------------#
max = 0;
for(i in y){
if(i>max){
max =i;
}
}
til = matrix(1:max*m,m,max)
til[,] = 0;
h = NROW(y)
for(p in 1:h){
yi = y[p]
til[p,yi] = 1;
}
#initializing theta
classes = max;
feature = n
#count occurnce
count = sum(til[,1])
example = 1;
alpha = .0001;
theta = matrix(1:max*n,classes,feature)
##########################7 rows x   54 column
theta[,] = 0;
theta2 = theta;
#a =1;
#b =1;
#!/usr/bin/env Rscript
# your code must have this first line.
# Train code for logistic regression part goes here
args <- commandArgs(trailingOnly = TRUE)
file_name <- args[1]
modeltheta <- args[2]
file_name  = "H:/R workspace/assnmt2/files1/input22.csv";
modeltheta = "sol.txt";
input <- read.table(file_name,header = FALSE,sep = ",")
mat <- as.matrix(input);
dimn = dim(mat)
m = dimn[1]
n = dimn[2]-1
y = mat[,n+1]
mat = mat[,-(n+1)]
x = t(t(mat));
##################create more feature here if want
#for(j in 1:n){
#}
#dimn = dim(x)
#m = dimn[1]
#n = dimn[2]
#-----------------------------------------------------#
max = 0;
for(i in y){
if(i>max){
max =i;
}
}
til = matrix(1:max*m,m,max)
til[,] = 0;
h = NROW(y)
for(p in 1:h){
yi = y[p]
til[p,yi] = 1;
}
#initializing theta
classes = max;
feature = n
#count occurnce
count = sum(til[,1])
example = 1;
alpha = .0001;
theta = matrix(1:max*n,classes,feature)
##########################7 rows x   54 column
theta[,] = 0;
theta2 = theta;
#a =1;
#b =1;
write_csv(predictions, "rf_benchmark.csv")
setwd(H:/R workspace/assnmt4)
setwd("H:/R workspace/assnmt4")
labels <- as.factor(train[rows,1])
cle
clr
clear
# Creates a simple random forest benchmark
# Creates a simple random forest benchmark
library(randomForest)
library(readr)
set.seed(0)
numTrain <- 10000
numTrees <- 25
train <- read_csv("../input/train.csv")
test <- read_csv("../input/test.csv")
rows <- sample(1:nrow(train), numTrain)
labels <- as.factor(train[rows,1])
train <- train[rows,-1]
rf <- randomForest(train, labels, xtest=test, ntree=numTrees)
predictions <- data.frame(ImageId=1:nrow(test), Label=levels(labels)[rf$test$predicted])
head(predictions)
write_csv(predictions, "rf_benchmark.csv")
library(randomForest)
library(readr)
library(randomForest)
library(readr)
library(randomForest)
library(readr)
library(readr)
# Creates a simple random forest benchmark
library(randomForest)
library(readr)
set.seed(0)
numTrain <- 10000
numTrees <- 25
train <- read_csv("../input/train.csv")
test <- read_csv("../input/test.csv")
rows <- sample(1:nrow(train), numTrain)
labels <- as.factor(train[rows,1])
train <- train[rows,-1]
rf <- randomForest(train, labels, xtest=test, ntree=numTrees)
predictions <- data.frame(ImageId=1:nrow(test), Label=levels(labels)[rf$test$predicted])
head(predictions)
write_csv(predictions, "rf_benchmark.csv")
# Creates a simple random forest benchmark
library(randomForest)
library(readr)
set.seed(0)
numTrain <- 10000
numTrees <- 25
train <- read_csv("../input/train.csv")
test <- read_csv("../input/test.csv")
train <- read_csv("input/train.csv")
test <- read_csv("input/test.csv")
rows <- sample(1:nrow(train), numTrain)
labels <- as.factor(train[rows,1])
train <- train[rows,-1]
rf <- randomForest(train, labels, xtest=test, ntree=numTrees)
predictions <- data.frame(ImageId=1:nrow(test), Label=levels(labels)[rf$test$predicted])
head(predictions)
write_csv(predictions, "rf_benchmark.csv")
rows <- sample(1:nrow(train), numTrain)
labels <- as.factor(train[rows,1])
train <- train[rows,-1]
rows <- sample(1:nrow(train), numTrain)
labels <- as.factor(train[rows,1])
labels = as.factor(train[rows,]$label)
train <- train[rows,-1]
clear
# Creates a simple random forest benchmark
library(randomForest)
library(readr)
set.seed(0)
numTrain <- 10000
numTrees <- 25
train <- read_csv("input/train.csv")
test <- read_csv("input/test.csv")
rows <- sample(1:nrow(train), numTrain)
labels = as.factor(train[rows,]$label)
train <- train[rows,-1]
rf <- randomForest(train, labels, xtest=test, ntree=numTrees)
predictions <- data.frame(ImageId=1:nrow(test), Label=levels(labels)[rf$test$predicted])
head(predictions)
write_csv(predictions, "rf_benchmark.csv")
# Creates a simple random forest benchmark
# this is the first program based on the randomforest library
# this idea is picked up from the discussion forum of kaggle
# using the random forest library of the random forest
library(randomForest)
library(readr)
set.seed(0)
# read the file form the input folder
trainingfile  = "input/train.csv"
testingfile = "input/test.csv";
inputtrain = read_csv(trainingfile)
inputest  = read_csv(testingfile)
# how many train file
NoofTrain = 10000
# how many trees to make
NoofTrees = 25
#extracting the pixel from the answer in the training data
data = sample(1:nrow(inputtrain), NoofTrain)
Answer = as.factor(inputtrain[data,]$label)
inputtrain = inputtrain[rows,-1]
# this is from the library of the random forest
#this was used t oamke predictions
result = randomForest(inputtrain, Answer, xtest=inputtest, ntree=NoofTrees)
predictions = data.frame(ImageId=1:nrow(inputtest), Label=levels(Answer)[result$inputtest$predicted])
head(predictions)
write_csv(predictions, "rf_benchmark.csv")
# Creates a simple random forest benchmark
# this is the first program based on the randomforest library
# this idea is picked up from the discussion forum of kaggle
# using the random forest library of the random forest
library(randomForest)
library(readr)
set.seed(0)
# read the file form the input folder
trainingfile  = "input/train.csv"
testingfile = "input/test.csv";
inputtrain = read_csv(trainingfile)
inputtest  = read_csv(testingfile)
# how many train file
NoofTrain = 10000
# how many trees to make
NoofTrees = 25
#extracting the pixel from the answer in the training data
data = sample(1:nrow(inputtrain), NoofTrain)
Answer = as.factor(inputtrain[data,]$label)
inputtrain = inputtrain[rows,-1]
# this is from the library of the random forest
#this was used t oamke predictions
result = randomForest(inputtrain, Answer, xtest=inputtest, ntree=NoofTrees)
predictions = data.frame(ImageId=1:nrow(inputtest), Label=levels(Answer)[result$inputtest$predicted])
head(predictions)
write_csv(predictions, "rf_benchmark.csv")
# Creates a simple random forest benchmark
# this is the first program based on the randomforest library
# this idea is picked up from the discussion forum of kaggle
# using the random forest library of the random forest
library(randomForest)
library(readr)
set.seed(0)
# read the file form the input folder
trainingfile  = "input/train.csv"
testingfile = "input/test.csv";
inputtrain = read_csv(trainingfile)
inputtest  = read_csv(testingfile)
# how many train file
NoofTrain = 10000
# how many trees to make
NoofTrees = 25
#extracting the pixel from the answer in the training data
data = sample(1:nrow(inputtrain), NoofTrain)
Answer = as.factor(inputtrain[data,]$label)
inputtrain = inputtrain[rows,-1]
# this is from the library of the random forest
#this was used t oamke predictions
inputtrain = inputtrain[data,-1]
# Creates a simple random forest benchmark
# this is the first program based on the randomforest library
# this idea is picked up from the discussion forum of kaggle
# using the random forest library of the random forest
library(randomForest)
library(readr)
set.seed(0)
# read the file form the input folder
trainingfile  = "input/train.csv"
testingfile = "input/test.csv";
inputtrain = read_csv(trainingfile)
inputtest  = read_csv(testingfile)
# how many train file
NoofTrain = 10000
# how many trees to make
NoofTrees = 25
#extracting the pixel from the answer in the training data
data = sample(1:nrow(inputtrain), NoofTrain)
Answer = as.factor(inputtrain[data,]$label)
inputtrain = inputtrain[data,-1]
# this is from the library of the random forest
#this was used t oamke predictions
#--------------------------------------------------------# same above loading data
result = randomForest(inputtrain, Answer, xtest=inputtest, ntree=NoofTrees)
predictions = data.frame(ImageId=1:nrow(inputtest), Label=levels(Answer)[result$inputtest$predicted])
head(predictions)
write_csv(predictions, "rf_benchmark.csv")
write_csv(predictions, "rf_benchmark.csv")
# Creates a simple random forest benchmark
library(randomForest)
library(readr)
set.seed(0)
numTrain <- 10000
numTrees <- 25
train <- read_csv("../input/train.csv")
test <- read_csv("../input/test.csv")
rows <- sample(1:nrow(train), numTrain)
labels = as.factor(train[rows,]$label)
train <- train[rows,-1]
rf <- randomForest(train, labels, xtest=test, ntree=numTrees)
predictions <- data.frame(ImageId=1:nrow(test), Label=levels(labels)[rf$test$predicted])
head(predictions)
write_csv(predictions, "rf_benchmark.csv")
# Creates a simple random forest benchmark
library(randomForest)
library(readr)
set.seed(0)
numTrain <- 10000
numTrees <- 25
train <- read_csv("input/train.csv")
test <- read_csv("input/test.csv")
rows <- sample(1:nrow(train), numTrain)
labels = as.factor(train[rows,]$label)
train <- train[rows,-1]
rf <- randomForest(train, labels, xtest=test, ntree=numTrees)
predictions <- data.frame(ImageId=1:nrow(test), Label=levels(labels)[rf$test$predicted])
head(predictions)
write_csv(predictions, "rf_benchmark.csv")
# Creates a simple random forest benchmark
# this is the first program based on the randomforest library
# this idea is picked up from the discussion forum of kaggle
# using the random forest library of the random forest
library(randomForest)
library(readr)
set.seed(0)
# read the file form the input folder
trainingfile  = "input/train.csv"
testingfile = "input/test.csv";
inputtrain = read_csv(trainingfile)
inputtest  = read_csv(testingfile)
# how many train file
NoofTrain = 10000
# how many trees to make
NoofTrees = 25
#extracting the pixel from the answer in the training data
data = sample(1:nrow(inputtrain), NoofTrain)
Answer = as.factor(inputtrain[data,]$label)
inputtrain = inputtrain[rows,-1]
# this is from the library of the random forest
#this was used t oamke predictions
result = randomForest(inputtrain, Answer, xtest=inputtest, ntree=NoofTrees)
predictions=data.frame(ImageId=1:nrow(inputtest),
Label=levels(Answer)[result$inputtest$predicted])
head(predictions)
write_csv(predictions, "rf_benchmark.csv")
# Creates a simple random forest benchmark
# this is the first program based on the randomforest library
# this idea is picked up from the discussion forum of kaggle
# using the random forest library of the random forest
library(randomForest)
library(readr)
set.seed(0)
# read the file form the input folder
trainingfile  = "input/train.csv"
testingfile = "input/test.csv";
inputtrain = read_csv(trainingfile)
inputtest  = read_csv(testingfile)
# how many train file
NoofTrain = 10000
# how many trees to make
NoofTrees = 25
#extracting the pixel from the answer in the training data
Daata = sample(1:nrow(inputtrain), NoofTrain)
Answer = as.factor(inputtrain[Daata,]$label)
inputtrain = inputtrain[rows,-1]
# this is from the library of the random forest
#this was used t oamke predictions
result = randomForest(inputtrain, Answer, xtest=inputtest, ntree=NoofTrees)
predictions=data.frame(ImageId=1:nrow(inputtest),
Label=levels(Answer)[result$inputtest$predicted])
head(predictions)
write_csv(predictions, "rf_benchmark.csv")
# Creates a simple random forest benchmark
# this is the first program based on the randomforest library
# this idea is picked up from the discussion forum of kaggle
# using the random forest library of the random forest
library(randomForest)
library(readr)
set.seed(0)
# read the file form the input folder
trainingfile  = "input/train.csv"
testingfile = "input/test.csv";
inputtrain = read_csv(trainingfile)
inputtest  = read_csv(testingfile)
# how many train file
NoofTrain = 10000
# how many trees to make
NoofTrees = 25
#extracting the pixel from the answer in the training data
Daata = sample(1:nrow(inputtrain), NoofTrain)
Answer = as.factor(inputtrain[Daata,]$label)
inputtrain = inputtrain[Daata,-1]
# this is from the library of the random forest
#this was used t oamke predictions
result = randomForest(inputtrain, Answer, xtest=inputtest, ntree=NoofTrees)
predictions=data.frame(ImageId=1:nrow(inputtest),
Label=levels(Answer)[result$inputtest$predicted])
head(predictions)
write_csv(predictions, "rf_benchmark.csv")
write_csv(predictions, "rf_benchmark.csv")
# Creates a simple random forest benchmark
library(randomForest)
library(readr)
set.seed(0)
numTrain <- 10000
numTrees <- 25
train <- read_csv("input/train.csv")
test <- read_csv("input/test.csv")
rows <- sample(1:nrow(train), numTrain)
labels = as.factor(train[rows,]$label)
train <- train[rows,-1]
rf <- randomForest(train, labels, xtest=test, ntree=numTrees)
predictions <- data.frame(ImageId=1:nrow(test), Label=levels(labels)[rf$test$predicted])
head(predictions)
write_csv(predictions, "rf_benchmark.csv")
